{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hbBerVq02hA"
      },
      "source": [
        " # LLM-Based Uncertainty Classification for Earnings Call Transcripts\n",
        "\n",
        "\n",
        "\n",
        " This notebook classifies question-answer pairs from earnings calls into three uncertainty levels:\n",
        "\n",
        " - **No Uncertainty**: Clear, definitive statements\n",
        "\n",
        " - **Intermediate Uncertainty**: Some hedging or conditional language\n",
        "\n",
        " - **High Uncertainty**: Explicit lack of visibility, wide outcome ranges, inability to estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP0k511D02hE"
      },
      "source": [
        " ## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-0s1PvR02hE",
        "outputId": "89ec355a-1c7a-4004-f027-f16de55c7511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.49.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch accelerate bitsandbytes pandas tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CjuW2ou202hF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Literal\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiH2srwL02hF"
      },
      "source": [
        " ## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2hslGXhl02hF"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ClassifierConfig:\n",
        "    \"\"\"Configuration for the uncertainty classifier.\"\"\"\n",
        "    model_path: str\n",
        "    device: str = \"auto\"\n",
        "    torch_dtype: str = \"auto\"  # \"auto\", \"float16\", \"bfloat16\", \"float32\"\n",
        "    load_in_8bit: bool = False\n",
        "    load_in_4bit: bool = False\n",
        "    max_new_tokens: int = 500\n",
        "    temperature: float = 0.1  # Low temperature for consistent classification\n",
        "\n",
        "# Example configurations for popular models\n",
        "EXAMPLE_CONFIGS = {\n",
        "    \"llama3-8b\": ClassifierConfig(\n",
        "        model_path=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "        load_in_8bit=True\n",
        "    ),\n",
        "    \"mistral-7b\": ClassifierConfig(\n",
        "        model_path=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "        load_in_8bit=True\n",
        "    ),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImlmAz0302hG"
      },
      "source": [
        " ## 3. Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1NQFgR2s02hG"
      },
      "outputs": [],
      "source": [
        "CLASSIFICATION_PROMPT = \"\"\"You are an expert financial analyst specializing in analyzing earnings call transcripts.\n",
        "\n",
        "TASK: Classify the uncertainty level in the following Question-Answer pair from an earnings call.\n",
        "\n",
        "DEFINITION OF UNCERTAINTY:\n",
        "- Uncertainty measures second-moment uncertainty: lack of visibility, conditionality, inability to estimate, or wide range of possible outcomes.\n",
        "- Do not treat positive/negative sentiment or clear numeric guidance as uncertainty by itself.\n",
        "- Focus on whether the speaker expresses confidence in their knowledge/predictions vs. acknowledges limitations.\n",
        "\n",
        "CLASSIFICATION LABELS:\n",
        "- NO_UNCERTAINTY: Speaker provides clear, definitive information with confidence. No hedging about visibility or outcomes.\n",
        "- INTERMEDIATE_UNCERTAINTY: Some hedging language, mild conditionality, or acknowledgment of moderate unknowns, but still provides substantive guidance.\n",
        "- HIGH_UNCERTAINTY: Explicit statements about lack of visibility, inability to estimate, dependence on unknown factors, or wide range of possible outcomes.\n",
        "\n",
        "QUESTION-ANSWER PAIR:\n",
        "<question>\n",
        "{question}\n",
        "</question>\n",
        "\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analyze the answer for indicators of second-moment uncertainty.\n",
        "2. Provide a brief reasoning (maximum 5 sentences).\n",
        "3. Output your final classification.\n",
        "\n",
        "REQUIRED OUTPUT FORMAT:\n",
        "```json\n",
        "{{\n",
        "    \"reasoning\": \"<your reasoning here, max 5 sentences>\",\n",
        "    \"classification\": \"<NO_UNCERTAINTY|INTERMEDIATE_UNCERTAINTY|HIGH_UNCERTAINTY>\"\n",
        "}}\n",
        "```\n",
        "\n",
        "Your response:\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYODbo2y02hG"
      },
      "source": [
        " ## 4. Uncertainty Classifier Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "unmkkOGI02hG"
      },
      "outputs": [],
      "source": [
        "class EarningsCallUncertaintyClassifier:\n",
        "    \"\"\"Classifies uncertainty in earnings call Q&A pairs using a HuggingFace LLM.\"\"\"\n",
        "\n",
        "    VALID_LABELS = [\"NO_UNCERTAINTY\", \"INTERMEDIATE_UNCERTAINTY\", \"HIGH_UNCERTAINTY\"]\n",
        "\n",
        "    def __init__(self, config: ClassifierConfig):\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the model and tokenizer from HuggingFace.\"\"\"\n",
        "        print(f\"Loading model: {self.config.model_path}\")\n",
        "\n",
        "        # Determine dtype\n",
        "        if self.config.torch_dtype == \"auto\":\n",
        "            dtype = \"auto\"\n",
        "        elif self.config.torch_dtype == \"float16\":\n",
        "            dtype = torch.float16\n",
        "        elif self.config.torch_dtype == \"bfloat16\":\n",
        "            dtype = torch.bfloat16\n",
        "        else:\n",
        "            dtype = torch.float32\n",
        "\n",
        "        # Load tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.config.model_path,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        # Load model with quantization options\n",
        "        load_kwargs = {\n",
        "            \"device_map\": self.config.device,\n",
        "            \"trust_remote_code\": True,\n",
        "        }\n",
        "\n",
        "        if dtype != \"auto\":\n",
        "            load_kwargs[\"torch_dtype\"] = dtype\n",
        "\n",
        "        if self.config.load_in_8bit:\n",
        "            load_kwargs[\"load_in_8bit\"] = True\n",
        "        elif self.config.load_in_4bit:\n",
        "            load_kwargs[\"load_in_4bit\"] = True\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.config.model_path,\n",
        "            **load_kwargs\n",
        "        )\n",
        "        print(\"Model loaded successfully!\")\n",
        "\n",
        "    def _format_prompt(self, question: str, answer: str) -> str:\n",
        "        \"\"\"Format the classification prompt with the Q&A pair.\"\"\"\n",
        "        return CLASSIFICATION_PROMPT.format(question=question, answer=answer)\n",
        "\n",
        "    def _apply_chat_template(self, prompt: str) -> str:\n",
        "        \"\"\"Apply chat template if available.\"\"\"\n",
        "        if hasattr(self.tokenizer, 'apply_chat_template'):\n",
        "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "            try:\n",
        "                return self.tokenizer.apply_chat_template(\n",
        "                    messages,\n",
        "                    tokenize=False,\n",
        "                    add_generation_prompt=True\n",
        "                )\n",
        "            except Exception:\n",
        "                pass\n",
        "        return prompt\n",
        "\n",
        "    def _parse_response(self, response: str) -> dict:\n",
        "        \"\"\"Parse the model's JSON response.\"\"\"\n",
        "        # Try to extract JSON from the response\n",
        "        json_match = re.search(r'```json\\s*(.*?)\\s*```', response, re.DOTALL)\n",
        "        if json_match:\n",
        "            json_str = json_match.group(1)\n",
        "        else:\n",
        "            # Try to find JSON without code blocks\n",
        "            json_match = re.search(r'\\{[^{}]*\"classification\"[^{}]*\\}', response, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group(0)\n",
        "            else:\n",
        "                # Fallback: try to extract classification directly\n",
        "                for label in self.VALID_LABELS:\n",
        "                    if label in response.upper():\n",
        "                        return {\n",
        "                            \"reasoning\": \"Could not parse structured response.\",\n",
        "                            \"classification\": label,\n",
        "                            \"parse_success\": False\n",
        "                        }\n",
        "                return {\n",
        "                    \"reasoning\": \"Failed to parse response.\",\n",
        "                    \"classification\": \"PARSE_ERROR\",\n",
        "                    \"parse_success\": False\n",
        "                }\n",
        "\n",
        "        try:\n",
        "            parsed = json.loads(json_str)\n",
        "            classification = parsed.get(\"classification\", \"\").upper().strip()\n",
        "\n",
        "            # Normalize classification\n",
        "            if classification not in self.VALID_LABELS:\n",
        "                # Try partial matching\n",
        "                for label in self.VALID_LABELS:\n",
        "                    if label in classification or classification in label:\n",
        "                        classification = label\n",
        "                        break\n",
        "\n",
        "            return {\n",
        "                \"reasoning\": parsed.get(\"reasoning\", \"\"),\n",
        "                \"classification\": classification if classification in self.VALID_LABELS else \"PARSE_ERROR\",\n",
        "                \"parse_success\": classification in self.VALID_LABELS\n",
        "            }\n",
        "        except json.JSONDecodeError:\n",
        "            return {\n",
        "                \"reasoning\": \"JSON decode error.\",\n",
        "                \"classification\": \"PARSE_ERROR\",\n",
        "                \"parse_success\": False\n",
        "            }\n",
        "\n",
        "    def classify(self, question: str, answer: str) -> dict:\n",
        "        \"\"\"\n",
        "        Classify a single Q&A pair.\n",
        "\n",
        "        Returns:\n",
        "            dict with keys: reasoning, classification, raw_response, parse_success\n",
        "        \"\"\"\n",
        "        prompt = self._format_prompt(question, answer)\n",
        "        formatted = self._apply_chat_template(prompt)\n",
        "\n",
        "        inputs = self.tokenizer(formatted, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=self.config.max_new_tokens,\n",
        "                temperature=self.config.temperature,\n",
        "                do_sample=self.config.temperature > 0,\n",
        "                pad_token_id=self.tokenizer.pad_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "            )\n",
        "\n",
        "        # Decode only the new tokens\n",
        "        response = self.tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        result = self._parse_response(response)\n",
        "        result[\"raw_response\"] = response\n",
        "        return result\n",
        "\n",
        "    def classify_batch(self, qa_pairs: list[dict], show_progress: bool = True) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Classify multiple Q&A pairs.\n",
        "\n",
        "        Args:\n",
        "            qa_pairs: List of dicts with 'question' and 'answer' keys\n",
        "            show_progress: Whether to show progress bar\n",
        "\n",
        "        Returns:\n",
        "            DataFrame with classification results\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        iterator = tqdm(qa_pairs, desc=\"Classifying\") if show_progress else qa_pairs\n",
        "\n",
        "        for i, qa in enumerate(iterator):\n",
        "            result = self.classify(qa['question'], qa['answer'])\n",
        "            result['id'] = qa.get('id', i)\n",
        "            result['question'] = qa['question']\n",
        "            result['answer'] = qa['answer']\n",
        "            results.append(result)\n",
        "\n",
        "        return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAwOgDur02hH"
      },
      "source": [
        " ## 5. Example Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mDmTFlDu02hH"
      },
      "outputs": [],
      "source": [
        "# Sample earnings call Q&A pairs for testing\n",
        "SAMPLE_QA_PAIRS = [\n",
        "    {\n",
        "        \"id\": 1,\n",
        "        \"question\": \"Can you provide guidance on next quarter's revenue?\",\n",
        "        \"answer\": \"We expect revenue to be between $2.1 billion and $2.3 billion, driven by strong demand in our cloud segment and continued growth in enterprise subscriptions.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 2,\n",
        "        \"question\": \"What's your outlook on margins for the rest of the year?\",\n",
        "        \"answer\": \"It's really difficult to say at this point. There are so many moving pieces with supply chain costs, and we honestly don't have great visibility into how that's going to play out. It could go either way depending on factors largely outside our control.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 3,\n",
        "        \"question\": \"How do you see the competitive landscape evolving?\",\n",
        "        \"answer\": \"We're monitoring the situation closely. While we feel good about our position, there's some uncertainty around new entrants and how pricing dynamics might shift. We're prepared for multiple scenarios but can't predict exactly how things will unfold.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 4,\n",
        "        \"question\": \"What was the driver of the revenue miss this quarter?\",\n",
        "        \"answer\": \"The miss was primarily due to delayed enterprise deals that pushed into Q1. We closed $450 million less than expected, specifically from three large contracts that required additional legal review.\"\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = ClassifierConfig(\n",
        "    model_path=\"meta-llama/Meta-Llama-3-8B-Instruct\",  # <-- Change to your model\n",
        "    load_in_8bit=True,  # Use quantization for memory efficiency\n",
        "    temperature=0.1,    # Low temp for consistent classification\n",
        ")\n",
        "# Initialize the classifier\n",
        "classifier = EarningsCallUncertaintyClassifier(config)\n",
        "\n",
        "# Classify sample Q&A pairs\n",
        "results_df = classifier.classify_batch(SAMPLE_QA_PAIRS)"
      ],
      "metadata": {
        "id": "lLOszaJK-39y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il_TvC4K02hI",
        "outputId": "88bc86ef-f872-45d4-ba2c-33018fda7ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CLASSIFICATION RESULTS\n",
            "================================================================================\n",
            "\n",
            "--- Sample 1 ---\n",
            "Here is the analysis:\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"reasoning\": \"The answer provides a specific revenue range with a clear direction (upward) and a relatively narrow range ($2.1-2.3 billion). The language used is straightforward and lacks any hedging or conditionality. The speaker attributes the expected revenue to specific factors (strong demand in cloud segment and continued growth in enterprise subscriptions), indicating a high level of confidence in their prediction.\",\n",
            "    \"classification\": \"NO_UNCERTAINTY\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this answer, the speaker provides a clear and specific revenue range with a clear direction, indicating a high level of confidence in their prediction. The language used is straightforward and lacks any hedging or conditionality, which further supports the classification of NO_UNCERTAINTY.\n",
            "Q: Can you provide guidance on next quarter's revenue?...\n",
            "A: We expect revenue to be between $2.1 billion and $2.3 billion, driven by strong demand in our cloud ...\n",
            "\n",
            "Classification: NO_UNCERTAINTY\n",
            "Reasoning: The answer provides a specific revenue range with a clear direction (upward) and a relatively narrow range ($2.1-2.3 billion). The language used is straightforward and lacks any hedging or conditionality. The speaker attributes the expected revenue to specific factors (strong demand in cloud segment and continued growth in enterprise subscriptions), indicating a high level of confidence in their prediction.\n",
            "Parse Success: True\n",
            "\n",
            "--- Sample 2 ---\n",
            "Here is the analysis:\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"reasoning\": \"The speaker explicitly states that they don't have great visibility into supply chain costs, which implies a lack of knowledge about a critical factor affecting margins. The answer also mentions that the outcome is dependent on factors outside their control, indicating a high degree of uncertainty. The speaker's language is cautious and hedged, using phrases like 'it's really difficult to say' and 'it could go either way', which further reinforces the uncertainty.\",\n",
            "    \"classification\": \"HIGH_UNCERTAINTY\"\n",
            "}\n",
            "```\n",
            "Q: What's your outlook on margins for the rest of the year?...\n",
            "A: It's really difficult to say at this point. There are so many moving pieces with supply chain costs,...\n",
            "\n",
            "Classification: HIGH_UNCERTAINTY\n",
            "Reasoning: The speaker explicitly states that they don't have great visibility into supply chain costs, which implies a lack of knowledge about a critical factor affecting margins. The answer also mentions that the outcome is dependent on factors outside their control, indicating a high degree of uncertainty. The speaker's language is cautious and hedged, using phrases like 'it's really difficult to say' and 'it could go either way', which further reinforces the uncertainty.\n",
            "Parse Success: True\n",
            "\n",
            "--- Sample 3 ---\n",
            "Here is my analysis:\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"reasoning\": \"The answer acknowledges uncertainty around new entrants and pricing dynamics, indicating a lack of visibility and inability to predict the exact outcome. The speaker uses phrases such as'some uncertainty' and 'can't predict exactly how things will unfold', which suggest a level of uncertainty. However, the speaker also mentions being 'prepared for multiple scenarios', which implies some level of planning and preparation. Overall, the answer strikes a balance between acknowledging uncertainty and expressing a sense of preparedness.\",\n",
            "    \"classification\": \"INTERMEDIATE_UNCERTAINTY\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this answer, the speaker acknowledges uncertainty around the competitive landscape, but also expresses a sense of preparedness and planning. This suggests a moderate level of uncertainty, which falls under the INTERMEDIATE_UNCERTAINTY classification.\n",
            "Q: How do you see the competitive landscape evolving?...\n",
            "A: We're monitoring the situation closely. While we feel good about our position, there's some uncertai...\n",
            "\n",
            "Classification: INTERMEDIATE_UNCERTAINTY\n",
            "Reasoning: The answer acknowledges uncertainty around new entrants and pricing dynamics, indicating a lack of visibility and inability to predict the exact outcome. The speaker uses phrases such as'some uncertainty' and 'can't predict exactly how things will unfold', which suggest a level of uncertainty. However, the speaker also mentions being 'prepared for multiple scenarios', which implies some level of planning and preparation. Overall, the answer strikes a balance between acknowledging uncertainty and expressing a sense of preparedness.\n",
            "Parse Success: True\n",
            "\n",
            "--- Sample 4 ---\n",
            "Here is the analysis:\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"reasoning\": \"The answer provides specific details about the revenue miss, including the exact amount ($450 million) and the reason (delayed enterprise deals and three large contracts requiring additional legal review). The language used is clear and definitive, indicating a high level of confidence in the explanation. There is no hedging or conditionality in the answer, which suggests that the speaker has a clear understanding of the events that led to the revenue miss.\",\n",
            "    \"classification\": \"NO_UNCERTAINTY\"\n",
            "}\n",
            "```\n",
            "\n",
            "In this case, I classify the uncertainty level as NO_UNCERTAINTY because the answer provides clear and specific information about the revenue miss, with no indication of uncertainty or hedging. The speaker appears to have a high level of confidence in their explanation, which suggests a lack of uncertainty.\n",
            "Q: What was the driver of the revenue miss this quarter?...\n",
            "A: The miss was primarily due to delayed enterprise deals that pushed into Q1. We closed $450 million l...\n",
            "\n",
            "Classification: NO_UNCERTAINTY\n",
            "Reasoning: The answer provides specific details about the revenue miss, including the exact amount ($450 million) and the reason (delayed enterprise deals and three large contracts requiring additional legal review). The language used is clear and definitive, indicating a high level of confidence in the explanation. There is no hedging or conditionality in the answer, which suggests that the speaker has a clear understanding of the events that led to the revenue miss.\n",
            "Parse Success: True\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CLASSIFICATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for _, row in results_df.iterrows():\n",
        "    print(f\"\\n--- Sample {row['id']} ---\")\n",
        "    print(row['raw_response'])\n",
        "    print(f\"Q: {row['question'][:100]}...\")\n",
        "    print(f\"A: {row['answer'][:100]}...\")\n",
        "    print(f\"\\nClassification: {row['classification']}\")\n",
        "    print(f\"Reasoning: {row['reasoning']}\")\n",
        "    print(f\"Parse Success: {row['parse_success']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEbsNCEU02hI",
        "outputId": "a3f7c092-7f8f-4210-d619-eec76ffbca01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY STATISTICS\n",
            "================================================================================\n",
            "classification\n",
            "NO_UNCERTAINTY              2\n",
            "HIGH_UNCERTAINTY            1\n",
            "INTERMEDIATE_UNCERTAINTY    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "print(results_df['classification'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Q_goAa02hI",
        "outputId": "509b5b92-fb6e-41ee-84bc-88943b737309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to uncertainty_classifications.json\n"
          ]
        }
      ],
      "source": [
        "# Save results to JSON\n",
        "output_path = \"uncertainty_classifications.json\"\n",
        "results_df.to_json(output_path, orient=\"records\", indent=2)\n",
        "print(f\"Results saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_soSL3_02hI"
      },
      "source": [
        " ## 6. Load Your Own Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "64FSbtcg02hI"
      },
      "outputs": [],
      "source": [
        "def load_qa_pairs_from_json(filepath: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Load Q&A pairs from a JSON file.\n",
        "\n",
        "    Expected JSON format:\n",
        "    [\n",
        "        {\n",
        "            \"id\": 1,\n",
        "            \"question\": \"...\",\n",
        "            \"answer\": \"...\",\n",
        "            \"label\": \"NO_UNCERTAINTY\"  // optional, for evaluation\n",
        "        },\n",
        "        ...\n",
        "    ]\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to JSON file\n",
        "\n",
        "    Returns:\n",
        "        List of dicts ready for classification\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Validate required fields\n",
        "    for i, item in enumerate(data):\n",
        "        if 'question' not in item or 'answer' not in item:\n",
        "            raise ValueError(f\"Item {i} missing required 'question' or 'answer' field\")\n",
        "        if 'id' not in item:\n",
        "            item['id'] = i\n",
        "\n",
        "    return data\n",
        "\n",
        "# Example usage:\n",
        "# my_qa_pairs = load_qa_pairs_from_json(\"my_earnings_calls.json\")\n",
        "# my_results = classifier.classify_batch(my_qa_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 7. Analyze Classification Performance"
      ],
      "metadata": {
        "id": "9zq3D0yS7wSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifications(results_df: pd.DataFrame, label_col: str = \"label\") -> dict:\n",
        "    \"\"\"\n",
        "    Evaluate classification accuracy when ground truth labels are available.\n",
        "\n",
        "    Args:\n",
        "        results_df: DataFrame with 'classification' column from classifier\n",
        "        label_col: Column name containing true labels\n",
        "\n",
        "    Returns:\n",
        "        Dict containing evaluation metrics\n",
        "    \"\"\"\n",
        "    if label_col not in results_df.columns:\n",
        "        print(f\"No '{label_col}' column found. Skipping evaluation.\")\n",
        "        return None\n",
        "\n",
        "    # Filter out parse errors\n",
        "    valid_results = results_df[results_df['classification'] != 'PARSE_ERROR'].copy()\n",
        "    parse_rate = len(valid_results) / len(results_df)\n",
        "\n",
        "    labels = [\"NO_UNCERTAINTY\", \"INTERMEDIATE_UNCERTAINTY\", \"HIGH_UNCERTAINTY\"]\n",
        "\n",
        "    metrics = {\n",
        "        \"parse_success_rate\": parse_rate,\n",
        "        \"n_total\": len(results_df),\n",
        "        \"n_valid\": len(valid_results),\n",
        "        \"accuracy\": accuracy_score(valid_results[label_col], valid_results['classification']),\n",
        "        \"classification_report\": classification_report(\n",
        "            valid_results[label_col],\n",
        "            valid_results['classification'],\n",
        "            labels=labels,\n",
        "            output_dict=True\n",
        "        ),\n",
        "        \"confusion_matrix\": confusion_matrix(\n",
        "            valid_results[label_col],\n",
        "            valid_results['classification'],\n",
        "            labels=labels\n",
        "        ).tolist()\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "dKPt3r4E7zjH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Complete Pipeline\n"
      ],
      "metadata": {
        "id": "gFsGfTdM-jY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_pipeline(input_path: str, output_path: str, classifier) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Run the full classification pipeline from JSON input to JSON output.\n",
        "\n",
        "    Args:\n",
        "        input_path: Path to input JSON file with Q&A pairs\n",
        "        output_path: Path for output JSON file with results\n",
        "        classifier: Initialized EarningsCallUncertaintyClassifier\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with classification results\n",
        "    \"\"\"\n",
        "    # Load input data\n",
        "    qa_pairs = load_qa_pairs_from_json(input_path)\n",
        "    print(f\"Loaded {len(qa_pairs)} Q&A pairs from {input_path}\")\n",
        "\n",
        "    # Check if labels exist for evaluation\n",
        "    has_labels = 'label' in qa_pairs[0] if qa_pairs else False\n",
        "\n",
        "    # Run classification\n",
        "    results_df = classifier.classify_batch(qa_pairs)\n",
        "\n",
        "    # Merge labels if they exist\n",
        "    if has_labels:\n",
        "        results_df['label'] = [qa.get('label') for qa in qa_pairs]\n",
        "\n",
        "    # Prepare output structure\n",
        "    output_data = {\n",
        "        \"metadata\": {\n",
        "            \"model_path\": classifier.config.model_path,\n",
        "            \"temperature\": classifier.config.temperature,\n",
        "            \"n_samples\": len(results_df),\n",
        "            \"parse_success_rate\": (results_df['parse_success'].sum() / len(results_df))\n",
        "        },\n",
        "        \"results\": results_df.to_dict(orient=\"records\")\n",
        "    }\n",
        "\n",
        "    # Add evaluation metrics if labels exist\n",
        "    if has_labels:\n",
        "        metrics = evaluate_classifications(results_df, \"label\")\n",
        "        if metrics:\n",
        "            output_data[\"evaluation\"] = metrics\n",
        "\n",
        "    # Save to JSON\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    print(f\"Results saved to {output_path}\")\n",
        "    return results_df\n",
        "\n",
        "# Example usage:\n",
        "# results_df = run_full_pipeline(\n",
        "#     input_path=\"earnings_calls_input.json\",\n",
        "#     output_path=\"classification_results.json\",\n",
        "#     classifier=classifier\n",
        "# )"
      ],
      "metadata": {
        "id": "tSeSuOS2-Fjv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = run_full_pipeline(\n",
        "    input_path=\"sample-input.json\",\n",
        "    output_path=\"classification_results.json\",\n",
        "    classifier=classifier\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXLjymrP-iGS",
        "outputId": "2b7561a0-4e8a-42a4-e126-aea96b92d9b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 10 Q&A pairs from sample-input.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 10/10 [04:21<00:00, 26.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to classification_results.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}